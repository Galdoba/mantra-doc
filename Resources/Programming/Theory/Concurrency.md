---
updated_at: 2026-02-12T15:37:37.987+10:00
---
**Параллелизм** ({{Concurrency|concurrency}}) — это свойство программной системы, при котором несколько вычислительных процессов могут выполняться одновременно, перекрываясь во времени. Параллелизм обеспечивает способность программы обрабатывать множество задач «одновременно», даже на одном процессорном ядре, за счёт переключения контекста, либо действительно параллельно на многоядерных архитектурах.

В отличие от параллелизма (parallelism), который означает физическое одновременное выполнение, параллелизм — это логическое свойство композиции независимых вычислительных активностей.

### Назначение
Применение параллелизма позволяет достичь качественно новых характеристик программных систем:

*   **Утилизация ресурсов**. Пока одна задача ожидает ввода-вывода или завершения внешней операции, процессор может выполнять другие задачи, повышая общую пропускную способность.
*   **Отзывчивость ([[Responsiveness|responsiveness]])**. Графические интерфейсы и серверные приложения могут оставаться отзывчивыми для пользователя, выполняя длительные операции в фоновом режиме.
*   **Масштабирование**. Программа может использовать возможности многоядерных процессоров для ускорения вычислений за счёт параллельного выполнения независимых частей задачи.
*   **Естественное моделирование предметной области**. Многие бизнес-процессы и физические системы по своей природе параллельны; их моделирование в коде требует средств параллелизма.

### Ограничения
Реализация параллелизма сопряжена с рядом фундаментальных сложностей и компромиссов:

1.  **[[Race Condition|Состояние гонки]]**. При некорректной синхронизации доступа к разделяемым данным результат выполнения зависит от непредсказуемого порядка чередования операций, что приводит к трудно воспроизводимым ошибкам.
2.  **[[Deadlock|Взаимная блокировка]]**. При неправильном использовании блокировок потоки могут бесконечно ожидать освобождения ресурсов, заблокированных друг другом.
3.  **[[Livelock|«Живая» блокировка]]**. Потоки не заблокированы, но постоянно меняют состояние в ответ на действия друг друга, не продвигаясь в выполнении.
4.  **[[Starvation|Голодание]]**. Некоторые потоки могут никогда не получить доступ к ресурсу из-за приоритетов или неудачной политики планирования.
5.  **Сложность отладки и тестирования**. Параллельные ошибки часто проявляются недетерминированно, зависят от времени и конкретной конфигурации выполнения, что делает их выявление и воспроизведение крайне трудными.
6.  **Накладные расходы**. Создание потоков, переключение контекста и синхронизация требуют дополнительных вычислительных ресурсов, что при неудачном проектировании может снизить производительность.

### Сложившиеся практики
Индустрия выработала множество подходов к управлению параллелизмом, позволяющих снизить риски и повысить надёжность:

1.  **Разделение на независимые задачи ([[Task|task]])**. Система декомпозируется на слабосвязанные единицы работы, которые могут выполняться параллельно без интенсивного обмена данными. Предпочтение отдаётся передаче сообщений, а не разделяемой памяти.

2.  **[[Immutability|Неизменяемые данные (immutability)]]**. Отказ от изменяемого разделяемого состояния полностью устраняет класс проблем, связанных с состоянием гонки. Если данные неизменны, синхронизация не требуется.

3.  **[[Actor Model|Модель акторов]]**. Параллелизм организуется как совокупность изолированных сущностей (акторов), каждый из которых обрабатывает сообщения последовательно, а взаимодействие осуществляется исключительно через асинхронную передачу сообщений без совместного использования памяти.

4.  **[[Communicating Sequential Processes|CSP (Communicating Sequential Processes)]]**. Модель, в которой параллельные процессы взаимодействуют через синхронные каналы (влияние языка Go, core.async). Процессы независимы и обмениваются данными только по каналам.

5.  **[[Structured Concurrency|Структурированный параллелизм (structured concurrency)]]**. Принцип, согласно которому время жизни параллельных задач должно быть вложено в синтаксические блоки кода. Родительская задача не завершается, пока не завершатся все порождённые дочерние задачи; отмены распространяются по иерархии. Реализован в Kotlin coroutines, Java Project Loom, Swift.

6.  **Асинхронное программирование ([[Asynchrony|asynchrony]])**. Вместо блокировки потока при ожидании операции ввода-вывода используется неблокирующий вызов с последующим уведомлением о завершении. Современные языки поддерживают синтаксис `async/await`, который позволяет писать асинхронный код в линейном стиле.

7.  **[[Thread Pool|Пул потоков (thread pool)]]**. Создание и уничтожение потоков — дорогостоящие операции. Практикой является использование заранее созданного пула рабочих потоков, которые переиспользуются для выполнения множества задач.

8.  **[[Fork-Join|Fork-Join]]**. Модель для рекурсивного параллелизма: задача разделяется (fork) на подзадачи, которые выполняются параллельно, затем результаты объединяются (join). Поддерживается в Java fork/join framework, параллельных stream’ах.

9.  **[[Lock-Free|Блокирующие и неблокирующие алгоритмы]]**. Для высоконагруженных систем разрабатываются алгоритмы на атомарных операциях сравнения с обменом (CAS), позволяющие обходиться без блокировок на уровне примитивов синхронизации.

10. **Избегание совместного состояния**. Архитектурные паттерны ([[CQRS|CQRS]], [[Event Sourcing|событийный сторинг]]) минимизируют конкурентные обновления одного агрегата, а транзакции, затрагивающие несколько сущностей, реализуются как саги с согласованностью в конечном счёте.

11. **Тестирование параллельного кода**. Используются специализированные инструменты и подходы:
    *   стресс-тестирование под высокой нагрузкой;
    *   санитайзеры потоков (ThreadSanitizer);
    *   статический анализ для выявления состояний гонки и взаимных блокировок;
    *   формальные модели и проверка моделей.

12. **Документирование модели параллелизма**. Явное описание того, какие данные разделяются, какие блокировки защищают какие ресурсы, какие гарантии предоставляют методы в многопоточной среде.

Таким образом, параллелизм является неизбежной сложностью в современных системах, но современные практики смещают акцент от явного управления потоками и блокировками к более декларативным, высокоуровневым моделям (акторы, CSP, структурированный параллелизм, асинхронность). Эти подходы не устраняют сложность полностью, но локализуют её, делая параллельные программы более надёжными и сопровождаемыми.